{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5yrjsY5bImOe"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "JRfbtm8GD2c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu3W-HHrc-L_",
        "outputId": "52c15528-0989-49ca-f9bf-2e0d45b07731"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access bz2 file\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "path = \"/content/drive/MyDrive/LLMs-Zero-to-Hero_bilibili/mobvoi_seq_monkey_general_open_corpus.jsonl.tar.bz2\"\n",
        "\n",
        "# # Open the tar.bz2 file\n",
        "# try:\n",
        "#     with tarfile.open(path, \"r:bz2\") as tar:\n",
        "#         # You can list the contents of the archive\n",
        "#         print(\"Contents of the archive:\")\n",
        "#         tar.list()\n",
        "\n",
        "#         # Or extract the contents to a directory\n",
        "#         # tar.extractall(\"/content/extracted_data\")\n",
        "#         # print(\"File extracted to /content/extracted_data\")\n",
        "\n",
        "# except tarfile.ReadError as e:\n",
        "#     print(f\"Error reading the tar file: {e}\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: File not found at {path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "en1SvPDbdMn-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvjf /content/drive/MyDrive/LLMs-Zero-to-Hero_bilibili/mobvoi_seq_monkey_general_open_corpus.jsonl.tar.bz2 -C /content/drive/MyDrive/LLMs-Zero-to-Hero_bilibili/\n"
      ],
      "metadata": {
        "id": "ft46tcxCeLvV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgnuBpbzUZ9W",
        "outputId": "c54213a1-fdb9-4553-9b9e-b9d14f4ff7a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dda84110db0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "\n",
        "torch.manual_seed(1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NPHhc0p8D2IM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defin GPT parameters"
      ],
      "metadata": {
        "id": "jNWKi2dTUzVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 512 # max sequence. The max length of a text\n",
        "    batch_size: int = 12\n",
        "    n_layer: int = 2\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768 # hidden_dim, hidden_size\n",
        "    hidden_dim = n_embd\n",
        "\n",
        "    # to tie_embedding_weight\n",
        "    dropout:float = 0.1\n",
        "    head_size = n_embd // n_head\n",
        "\n",
        "    # vocab_size takes certain length of word. 50257 is the default GPT choice\n",
        "    vocab_size = 50257"
      ],
      "metadata": {
        "id": "Lxdz3PJSUxEp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @dataclass\n",
        "# class GPTConfig:\n",
        "#     block_size: int = 512   # 这里其实应该是文本的最大长度（ max_seq_len）\n",
        "#     batch_size: int = 12\n",
        "#     n_layer: int = 6\n",
        "#     n_head: int = 12\n",
        "#     n_embd: int = 768    # n_embd 也叫 hidden_dim, hiden_size, 这里我同时设置了和 embed_dim 一样\n",
        "#     head_size: int = n_embd // n_head\n",
        "#     dropout: float = 0.1\n",
        "#     # # tiktoken 使用的是 GPT-2 的词表，大约有 50257 个token\n",
        "#     vocab_size: int = 50257"
      ],
      "metadata": {
        "id": "Gp4oR6lJPaTF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define the GPT structure"
      ],
      "metadata": {
        "id": "sVzfQp8YDuuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(config.hidden_dim, config.head_size)\n",
        "    self.value = nn.Linear(config.hidden_dim, config.head_size)\n",
        "    self.query = nn.Linear(config.hidden_dim, config.head_size)\n",
        "    self.head_size = config.head_size\n",
        "\n",
        "    # attention mask. Register with register_buffer.\n",
        "    # This helps save memory and process faster since no computing graidents\n",
        "    self.register_buffer(\n",
        "        \"attention_mask\",\n",
        "        #tril means bottom triagnle\n",
        "        # Block_size is 512\n",
        "        torch.tril(\n",
        "            torch.ones(config.block_size, config.block_size)\n",
        "        )\n",
        "    )\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    # forward mechanism\n",
        "  def forward(self, x):\n",
        "      batch_size, seq_len, hidden_dim = x.size()\n",
        "      k = self.key(x)\n",
        "      q = self.query(x)\n",
        "      v = self.value(x)\n",
        "      weight = q @ k.transpose(-2, -1) # @ is simple torch.matmul\n",
        "      weight = weight.masked_fill(\n",
        "          self.attention_mask[:seq_len, :seq_len] == 0,\n",
        "          float('-inf')\n",
        "      ) / math.sqrt(self.head_size)\n",
        "\n",
        "      # when compute wight, need divide by sqrt d_k\n",
        "      weight = F.softmax(weight, dim = -1)\n",
        "\n",
        "      # dropout ned place after weight\n",
        "      weight = self.dropout(weight)\n",
        "      return weight @ v\n",
        "\n",
        "# 2. multi haed attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [SingleHeadAttention(config)\n",
        "        for _ in range(config.n_head)\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    self.proj = nn.Linear(config.hidden_dim, config.hidden_dim)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = torch.cat(\n",
        "        [h(x) for h in self.heads],\n",
        "        dim = -1\n",
        "\n",
        "    )\n",
        "\n",
        "    output = self.proj(output)\n",
        "    output = self.dropout(output)\n",
        "    return output\n",
        "\n",
        "# 3 feed forward(MLP)\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        # refer to the flow chart, it has bottlent. Increase dim and decrease dim\n",
        "        nn.Linear(config.hidden_dim, 4 * config.hidden_dim), # Swiglu # 8/3\n",
        "        nn.GELU(),  # you may use nn.Relu() too\n",
        "        nn.Linear( 4*config.hidden_dim, config.hidden_dim),\n",
        "        nn.Dropout(config.dropout)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "\n",
        "# 4 block\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(config)\n",
        "    self.ffn = FeedForward(config)\n",
        "    self.ln1 = nn.LayerNorm(config.hidden_dim)\n",
        "    self.ln2 = nn.LayerNorm(config.hidden_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x +self.att(self.ln1(x))\n",
        "    x = x +self.ffn(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "# 5 GPT\n",
        "class GPT(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config # Store the config object\n",
        "\n",
        "    # (embedding, position, norm, mlp, block)\n",
        "    # position embedding from 0,1,xxx embedding upgrade to ROPE\n",
        "    # norm layer norm -> rms norm\n",
        "    # MLP -> Swiglu\n",
        "    # MHA -> GQA\n",
        "    self.token_embedding_table = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "    self.position_embedding_table = nn.Embedding(config.block_size, config.n_embd)\n",
        "    self.blocks = nn.Sequential(\n",
        "        # it has n blocks\n",
        "        *[Block(config) for _ in range(config.n_layer)]\n",
        "    )\n",
        "\n",
        "    self.ln_final = nn.LayerNorm(config.n_embd)\n",
        "    self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias = False)\n",
        "\n",
        "    # SLM models would use tie-weight to reduce embeeding parameters\n",
        "    # very important\n",
        "    # above, you see its from vocab size to n_embd, and n_embd to vocab_size. it works simplely with next line of code\n",
        "    # Because the linear layer, it is from dimension of 4 to 8, the weight's actual shape is 8 by 4\n",
        "    # xW^T\n",
        "\n",
        "    # self.token_embedding_table.weight = self.lm_head.weight\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # option A (my earlier suggestion; common in GPT code)\n",
        "    self.lm_head.weight = self.token_embedding_table.weight\n",
        "\n",
        "    # option B (equivalent)\n",
        "    self.token_embedding_table.weight = self.lm_head.weight\n",
        "\n",
        "    # Why do most repos do “A”?\n",
        "    # Convention.\n",
        "    # People usually think “output layer uses the same weights as the input embedding,”\n",
        "    # so they set the output to reference the embedding.\n",
        "    # Either direction is fine—just pick one and be consistent.\n",
        "    \"\"\"\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    if isinstance(module, nn.Linear):\n",
        "      # initialize eto normal distr\n",
        "      torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
        "      if module.bias is not None:\n",
        "        torch.nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "      torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
        "\n",
        "  def forward(self, idx, targets = None):\n",
        "    # dix input is token ids,\n",
        "    # target is target token ids\n",
        "    # shape are the same\n",
        "    batch, seq_len = idx.size()\n",
        "\n",
        "    assert seq_len <= self.config.block_size, \"seq_len is too long\"\n",
        "\n",
        "    token_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(\n",
        "        # mak sure pos token and input idx ae in th same devic\n",
        "        torch.arange(seq_len, device = idx.device)\n",
        "    )\n",
        "\n",
        "    # Question: token mbedding and position emebedding are addable?\n",
        "\n",
        "    x = token_emb +pos_emb\n",
        "    x = self.blocks(x)\n",
        "    x = self.ln_final(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      batch, seq_len, vocab_size = logits.size()\n",
        "      logits = logits.view(batch * seq_len, vocab_size)\n",
        "      targets = targets.view(batch * seq_len)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # 如果序列太长，只取最后 block_size 个token\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            # 获取预测\n",
        "            logits, _ = self(idx_cond)\n",
        "            # 只关注最后一个时间步的预测\n",
        "            logits = logits[:, -1, :]  # becomes (B, vocab_size)\n",
        "            # 应用softmax获取概率\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # 采样下一个token\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # 附加到序列上\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "HyoPk_VQWAd8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Construct input Dataset\n",
        "know the input value is importnat"
      ],
      "metadata": {
        "id": "ioYXeBV2dAn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tiktoken\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, path, block_size = 512):\n",
        "    self.enc = tiktoken.get_encoding(\"gpt2\")\n",
        "    self.block_size = block_size\n",
        "\n",
        "    self.eos_token = self.enc.encode(\n",
        "        \"<|endoftext|>\",\n",
        "        allowed_special = {\"<|endoftext|>\"}\n",
        "    )[0]\n",
        "\n",
        "\n",
        "\n",
        "    self.encoded_data = []\n",
        "    self.max_lines = 1000\n",
        "\n",
        "    raw_data = []\n",
        "    with open(path, 'r') as f:\n",
        "      for i, line in enumerate(f):\n",
        "        if i >= self.max_lines:\n",
        "          break\n",
        "\n",
        "        try:\n",
        "          text = json.loads(line.strip())['text']\n",
        "          raw_data.append(text)\n",
        "        except Exception as e:\n",
        "          continue\n",
        "\n",
        "    full_encoded = []\n",
        "    for text in raw_data:\n",
        "      encoded_text = self.enc.encode(text) # list\n",
        "      full_encoded.extend(encoded_text + [self.eos_token])\n",
        "\n",
        "    # block_size is 512\n",
        "    # long -> short (512)\n",
        "\n",
        "    for i in range(0, len(full_encoded), self.block_size):\n",
        "      chunk = full_encoded[i: i + self.block_size+1] # 512. Shift the it to right to 513\n",
        "      if len(chunk) < self.block_size + 1:\n",
        "        chunk = chunk + [self.eos_token] * (self.block_size +1 -len(chunk))\n",
        "      self.encoded_data.append(chunk)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    chunk = self.encoded_data[idx]\n",
        "    x = torch.tensor(chunk[:-1], dtype=torch.long)\n",
        "    y = torch.tensor(chunk[1:], dtype = torch.long)\n",
        "    return x,y\n",
        "\n",
        "  def encode(self, text):\n",
        "    return self.enc.encode(text)\n",
        "\n",
        "  def decode(self,ids):\n",
        "    return self.enc.decode(ids)\n",
        "\n"
      ],
      "metadata": {
        "id": "jGDiAGOiW5U-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some random test\n",
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "enc.encode(\n",
        "        \"<|endoftext|>\",\n",
        "        allowed_special = {\"<|endoftext|>\"}\n",
        "    )\n",
        "\n",
        "print(\"---------\")\n",
        "enc.encode(\n",
        "        \"<|endoftext|>\",\n",
        "        allowed_special = {\"<|endoftext|>\"}\n",
        "    )[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCP_ZYDX5nWA",
        "outputId": "c47bc0dd-6a59-4775-c0d1-1179f7854c22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Implementing related functions"
      ],
      "metadata": {
        "id": "iXc76N4anvBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## take look the dataset"
      ],
      "metadata": {
        "id": "5yrjsY5bImOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/LLMs-Zero-to-Hero_bilibili/mobvoi_seq_monkey_general_open_corpus.jsonl\"\n",
        "\n",
        "my_dataset = MyDataset(dataset_path, block_size=512)\n",
        "print(len(my_dataset))\n",
        "print(my_dataset[0])\n"
      ],
      "metadata": {
        "id": "wgtcJJLUn3Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e0b284-b501-4a14-fd65-d159cb22a70c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3700\n",
            "(tensor([28839,   101,   162,   253,    98, 13783,   226,   164,   247,   248,\n",
            "        28156,   222,   161,    95,   252,   161,   222,   120,   163,   101,\n",
            "          236, 10310,   241, 18796,   101, 20998,   239,   163,    98,   101,\n",
            "          162,    94,   230, 20015,   114, 40792,   171,   120,   234, 30585,\n",
            "          116, 30585,   116,   162,   114,   231, 20998,   232, 32573,   249,\n",
            "          165,    94,   117, 45911,   247,   162,   232,   113,   163,   101,\n",
            "          236,   165,    95,   251,   161,   240,   234,   163,   101,   236,\n",
            "          162,   105,   122,   162,   235,   253, 13783,   109, 21410,   164,\n",
            "          106,    97, 22522,   248,   161,   240,   234, 13783,   226, 49426,\n",
            "          228, 16764, 28839,   101,   164,   106,    94,   163,   106,   245,\n",
            "          163,   101,   236,   162,   105,   122,   162,   235,   253, 13783,\n",
            "          109, 33768,   114,   171,   120,   234, 17358,   223, 38834, 17358,\n",
            "          223, 49546, 32573,   249,   165,    94,   117, 45911,   247,   162,\n",
            "          232,   113,   163,   101,   236,   165,    95,   251, 44293,   227,\n",
            "          162,   233,   105, 28839,   101, 37863,   227,   171,   120,   253,\n",
            "          198, 43380,   117, 29826,    97,   171,   120,   234, 22522,   252,\n",
            "        27950,    94, 40792, 27764,   246, 28839,   101, 35707,   237,   164,\n",
            "          100,   223, 26344,   228, 29826,   100, 16764,   198, 17312,   231,\n",
            "        21689, 10310,   119, 28156,   254, 37605,   240, 33176,   114,   171,\n",
            "          120,   234, 39355,   111,   164,   106,    94,   163,   106,   245,\n",
            "          163,   101,   236,   162,   105,   122,   162,   235,   253, 13783,\n",
            "          109, 33768,   114, 44293,   227,   162,   233,   105, 32573,   249,\n",
            "          165,    94,   117, 45911,   247,   162,   232,   113,   163,   101,\n",
            "          236,   165,    95,   251,   171,   120,   249,   198, 17312,   231,\n",
            "        21689, 10310,   119, 28156,   254, 30298,    98,   163,    99,   119,\n",
            "          171,   120,   234, 39355,   111,   164,   106,    94,   163,   106,\n",
            "          245,   163,   101,   236,   162,   105,   122,   162,   235,   253,\n",
            "        13783,   109, 33768,   114, 30298,   242,   165,   247,    97, 32573,\n",
            "          249,   165,    94,   117, 45911,   247,   162,   232,   113,   163,\n",
            "          101,   236,   165,    95,   251, 16764, 26344,   228,   162,   252,\n",
            "          238, 32573,   247, 10310,   103, 29785,   106,   165,    95,   246,\n",
            "          171,   120,   234,   165,   250,   222, 17358,   223,   163,    94,\n",
            "          106, 22522,   248, 32573,   249,   165,    94,   117, 45911,   247,\n",
            "          162,   232,   113,   163,   101,   236,   165,    95,   251, 10310,\n",
            "          236,   163,   101,   236,   162,   105,   122,   162,   235,   253,\n",
            "        13783,   109, 45298, 29785,   112, 42468, 20015,   222, 20046,   230,\n",
            "        17739,   111,   163,   111,   119, 16764,   198, 49426,   228,   162,\n",
            "          116,   227, 32573,   247, 12859,   234, 38519, 45298, 29785,   112,\n",
            "        21410, 17739,   111,   163,   111,   119,   171,   120,   234,   165,\n",
            "           99,   244, 17739,   230,   165,   250,   222, 17358,   223, 12859,\n",
            "          228,   164,   100,    96,   161,    95,   252,   161,   222,   120,\n",
            "          163,   101,   236, 21410,   162,    99,   224, 33232,   113,   161,\n",
            "          240,   234, 17739, 35050,   232,   113, 33699,    96, 17312,   118,\n",
            "        26344,   114, 16764,   161,    95,   252,   161,   222,   120,   163,\n",
            "          101,   236, 42468, 20015,    98,   161,   243,   228,   161,   241,\n",
            "          223,   171,   120,   230,   164,   112,   100, 31965,   102, 23513,\n",
            "        17312,   235, 27950,    94,   163,   255,   231,   171,   120,   231,\n",
            "        28839,   101, 38184,   223,   164,   121,   105, 32573,   229,   163,\n",
            "          101,   233, 40792, 12859,   100, 37955, 21410,   161,    95,   252,\n",
            "          161,   222,   120,   165,    95,   251, 43291, 10310,   118,   164,\n",
            "          106,    94,   163,   101,   236,   160,   122,   251,   162,   235,\n",
            "          106, 32003]), tensor([  101,   162,   253,    98, 13783,   226,   164,   247,   248, 28156,\n",
            "          222,   161,    95,   252,   161,   222,   120,   163,   101,   236,\n",
            "        10310,   241, 18796,   101, 20998,   239,   163,    98,   101,   162,\n",
            "           94,   230, 20015,   114, 40792,   171,   120,   234, 30585,   116,\n",
            "        30585,   116,   162,   114,   231, 20998,   232, 32573,   249,   165,\n",
            "           94,   117, 45911,   247,   162,   232,   113,   163,   101,   236,\n",
            "          165,    95,   251,   161,   240,   234,   163,   101,   236,   162,\n",
            "          105,   122,   162,   235,   253, 13783,   109, 21410,   164,   106,\n",
            "           97, 22522,   248,   161,   240,   234, 13783,   226, 49426,   228,\n",
            "        16764, 28839,   101,   164,   106,    94,   163,   106,   245,   163,\n",
            "          101,   236,   162,   105,   122,   162,   235,   253, 13783,   109,\n",
            "        33768,   114,   171,   120,   234, 17358,   223, 38834, 17358,   223,\n",
            "        49546, 32573,   249,   165,    94,   117, 45911,   247,   162,   232,\n",
            "          113,   163,   101,   236,   165,    95,   251, 44293,   227,   162,\n",
            "          233,   105, 28839,   101, 37863,   227,   171,   120,   253,   198,\n",
            "        43380,   117, 29826,    97,   171,   120,   234, 22522,   252, 27950,\n",
            "           94, 40792, 27764,   246, 28839,   101, 35707,   237,   164,   100,\n",
            "          223, 26344,   228, 29826,   100, 16764,   198, 17312,   231, 21689,\n",
            "        10310,   119, 28156,   254, 37605,   240, 33176,   114,   171,   120,\n",
            "          234, 39355,   111,   164,   106,    94,   163,   106,   245,   163,\n",
            "          101,   236,   162,   105,   122,   162,   235,   253, 13783,   109,\n",
            "        33768,   114, 44293,   227,   162,   233,   105, 32573,   249,   165,\n",
            "           94,   117, 45911,   247,   162,   232,   113,   163,   101,   236,\n",
            "          165,    95,   251,   171,   120,   249,   198, 17312,   231, 21689,\n",
            "        10310,   119, 28156,   254, 30298,    98,   163,    99,   119,   171,\n",
            "          120,   234, 39355,   111,   164,   106,    94,   163,   106,   245,\n",
            "          163,   101,   236,   162,   105,   122,   162,   235,   253, 13783,\n",
            "          109, 33768,   114, 30298,   242,   165,   247,    97, 32573,   249,\n",
            "          165,    94,   117, 45911,   247,   162,   232,   113,   163,   101,\n",
            "          236,   165,    95,   251, 16764, 26344,   228,   162,   252,   238,\n",
            "        32573,   247, 10310,   103, 29785,   106,   165,    95,   246,   171,\n",
            "          120,   234,   165,   250,   222, 17358,   223,   163,    94,   106,\n",
            "        22522,   248, 32573,   249,   165,    94,   117, 45911,   247,   162,\n",
            "          232,   113,   163,   101,   236,   165,    95,   251, 10310,   236,\n",
            "          163,   101,   236,   162,   105,   122,   162,   235,   253, 13783,\n",
            "          109, 45298, 29785,   112, 42468, 20015,   222, 20046,   230, 17739,\n",
            "          111,   163,   111,   119, 16764,   198, 49426,   228,   162,   116,\n",
            "          227, 32573,   247, 12859,   234, 38519, 45298, 29785,   112, 21410,\n",
            "        17739,   111,   163,   111,   119,   171,   120,   234,   165,    99,\n",
            "          244, 17739,   230,   165,   250,   222, 17358,   223, 12859,   228,\n",
            "          164,   100,    96,   161,    95,   252,   161,   222,   120,   163,\n",
            "          101,   236, 21410,   162,    99,   224, 33232,   113,   161,   240,\n",
            "          234, 17739, 35050,   232,   113, 33699,    96, 17312,   118, 26344,\n",
            "          114, 16764,   161,    95,   252,   161,   222,   120,   163,   101,\n",
            "          236, 42468, 20015,    98,   161,   243,   228,   161,   241,   223,\n",
            "          171,   120,   230,   164,   112,   100, 31965,   102, 23513, 17312,\n",
            "          235, 27950,    94,   163,   255,   231,   171,   120,   231, 28839,\n",
            "          101, 38184,   223,   164,   121,   105, 32573,   229,   163,   101,\n",
            "          233, 40792, 12859,   100, 37955, 21410,   161,    95,   252,   161,\n",
            "          222,   120,   165,    95,   251, 43291, 10310,   118,   164,   106,\n",
            "           94,   163,   101,   236,   160,   122,   251,   162,   235,   106,\n",
            "        32003,   234]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = []\n",
        "with open(dataset_path, 'r') as f:\n",
        "  for i, line in enumerate(f):\n",
        "    if i >= 1000:\n",
        "      break\n",
        "\n",
        "    try:\n",
        "      text = json.loads(line.strip())['text']\n",
        "      raw_data.append(text)\n",
        "    except Exception as e:\n",
        "      continue\n",
        "\n",
        "raw_data[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlOsI3MlA0a8",
        "outputId": "07af3f3b-60c3-4c33-e66a-955bc0caa068"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['在查处虚开增值税专用发票案件中，常常涉及进项留抵税额和税款损失的认定和处理。在计算税款损失时，要不要将进项留抵税额包括在内？\\n对此，实务中存在意见分歧。\\n有人主张归并，即计算税款损失时包括进项留抵税额；\\n有人主张剥离，即计算税款损失时剔除进项留抵税额。分析这个问题，需要确定进项留抵税额与税款损失之间是什么关系。\\n理清这二者之间的关系，首先需要了解增值税的概念和其抵扣机制。增值税是以商品（货物、服务等）在流转过程中产生的增值额作为计税依据而征收的一种流转税。为避免重复征税，在增值税中存在抵扣链条机制。\\n一般而言，交易上游企业缴纳的税额，交易下游企业可以对相应的税额进行抵扣。\\n对增值税一般纳税人来说，其购进货物、服务等取得增值税专用发票，发票上的税额是进项税额。\\n其出售货物、服务等，向购买方开具增值税专用发票，发票的税额是销项税额。\\n一般情况下，销项税额减去进项税额的金额是应纳税额，企业根据应纳税额按期申报纳税。\\n其次需要了解进项留抵税额的概念及产生原因。\\n在计算销项税额和进项税额的差额时，有时会出现负数，即当期进项税额大于当期销项税额。这个差额在当期未实现抵扣，为进项留抵税额，在以后纳税人有销项税额时再进行抵扣。\\n企业产生进项留抵税额的主要原因是其进项税额和销项税额时间上的不一致。\\n例如，企业前期集中采购货物和服务，投资大，销项税率低于进项税率等。\\n从税款抵扣的角度看，进项留抵税额只是购进的这部分进项税额参与到增值税应纳税额的计算过程中，但是其对应的进项税额抵扣还未真正实现，一般要等到其未来有相应的销项税额时，才能真正实现进项税额抵扣。\\n可见，进项留抵税额处于不确定状态，能否抵扣受到很多因素影响，例如企业经营中断，没有销项税额，这时进项留抵税额就无法实现抵扣。但如果企业按照税收政策规定申请进项留抵退税，进项税额抵扣就随之实现。\\n最后需要了解税款损失的概念。\\n税款损失，通常是指因虚开增值税专用发票，导致国家税款被骗或者流失的金额。关于税款损失，实务中有多种表述。\\n例如，北京大学法学院教授陈兴良曾谈到虚开行为本身不会造成国家税款损失，只有利用发票抵扣时才会造成国家税款损失。刘兵等编著的《虚开增值税专用发票案例司法观点和案例解析》一书中提到：“给国家税款造成损失的数额，实际上就是被骗取的国家税款在侦查终结以前无法追回的部分。”\\n赵清海与王家欣合著的《增值税专用发票虚开的判定与预防》一书中提到：“司法实践中，受票方用虚开的增值税专用发票予以抵扣的税款，从而导致受票方应纳税额的减少是法院所认定的国家税款流失的金额。”\\n从这些表述可见，税款损失应该是实际造成的损失，不应包括不确定的部分——进项留抵税额，进项留抵税额与税款损失之间不能直接画等号。\\n综上分析，进项留抵税额，只是使国家税款处于可能被抵扣的状态，还没有真正造成国家税款流失，一般情况下应将其从税款损失中剥离，特殊条件下将其归并入税款损失。\\n例如，当纳税人造假按照税收政策规定申请进项留抵税额退税后，有关税款损失将会从危险状态转化成危害结果，这时候要将有关进项留抵税额并入税款损失。\\n所以，在虚开增值税专用发票案件中，一般情况下，如果以纳税人的进项税额作为税款损失的计算基数，在对其进行行政处罚或刑事处罚时，应把进项留抵税额从税款损失中剔除，但纳税人申请进项留抵退税的除外。这样处理，把处罚与危害结果相对应，体现行政处罚法的过罚相当原则和刑法的罚当其罪原则。',\n",
              " '读者在使用本《年鉴》时发现与以前本局出版、公布、或内部提供的资料有出入的，概以本《年鉴》为准。\\n《年鉴》正文内容分为三大部分。第一部分为文字部分，收录了《2012年政府工作报告》以及《2011年河源市国民经济和社会发展统计公报》。第二部分为统计图，形象地反映建市以来河源市国民经济发展变化情况。第三部分为统计资料，具体分为行政区划和自然资源，综合、核算、人口，农村经济，工业，能源，交通、邮电，贸易业、物价指数，对外经济、旅游，财政、金融和保险，固定资产投资与建筑业，劳动工资，人民生活，文教、卫生和其他，河源市乡镇主要经济指标，广东省县域主要经济指标,广东省各市主要经济指标等16部分。此外，为便于读者正确理解和使用统计资料，特附主要统计指标解释、统计术语简介及统计法律法规等资料。\\n《年鉴》中，本市的数据是根据我局及有关部门的统计年报整理汇编而成，由于某些专业统计制度和统计口径的变化，有些数据空缺。使用本《年鉴》时，请注意指标名称的含义、统计口径、统计范围、计算单位、可比价与现行价(当年价)等。\\n《年鉴》第一部分中的有些数据为初步统计数，凡与本《年鉴》中第三部分的数据有出入的，则以第三部分的统计数据为准。\\n本《年鉴》部分统计数据使用了四舍五入的进位方法，因此，可能令统计表内个别项目相加与总数略有出入。\\n本《年鉴》统计表中符号使用说明：“＃”表示其中主要项；“空格”表示该项统计指标数据不详或无该项数据。\\n本《年鉴》的编辑出版，得到县、区及市直有关部门和单位的大力支持，在此表示感谢！本书疏漏之处敬请批评指正。\\n下载说明： �本站下载的文件一律为压缩文件，请使用 WinRAR 解压。\\n�PDF格式的资料请使用 Adobe Reader 浏览。\\n�本站提供的一些资料是供学习研究之用，如用于商业用途，请购买正版。',\n",
              " '初中阶段是学生身心发育的一个突变期。尤其是初一学生，从小学到中学，随着环境改变，课程增多，难度加大，他们内心发生了急剧变化，产生了许多烦恼、困惑，造成较大的心理偏差，这就需要教师和家长及时给予心理指导和帮助。\\n一、心理偏差的种种表现\\n1、骄傲自负心理。这种心理偏差主要表现在思维敏捷、小学成绩拔尖的学生身上，特别是一些长期担任班干部、竞赛获奖、父母有权力的学生表现尤为明显。\\n2．单纯求趣心理。求趣激趣，这是教学的原则之一，但是，有些初一学生过分地追求接受知识要符合自己的兴趣，还想回到幼儿园、小学时“游戏教育”和“愉快教育”中去，不能努力适应初中阶段的学习生活。\\n3．自卑孤僻心理。多数来自普通工薪家庭及农村贫困地区或遭遇父母婚变的学生，往往在干部、富家子弟、有特长的同学面前感到自卑，心理压抑，行为孤僻，甚至变态的自尊，影响学习。\\n4．胆怯畏惧心理。部分性格内向、胆小的学生，主要是女生，羞于用语言表达思想，沉溺于内心活动和笔头表达。内心活动不能外显，妨碍了思维素质的深入发展。\\n5．浮躁马虎心理。部分活泼好动的学生，智力水平不低，但就是不能静下心学习，总是浅尝辄止，马虎应付，不愿作深入的思考，常常“半罐水响叮当”。\\n6．贪图享受心理。一些家境较好的学生，行为懒散，好逸恶劳，学习上畏难怕苦，生活上讲吃讲穿。\\n二、上述心理偏差的形成原因\\n1．生理上的原因。初中学生处于发育高峰期，身高体重剧增，性发育开始。生理上的急剧变化使儿童意识到自己不再是孩子，“成人感”增强。但是，青年身体成熟速度存在着很大的个体差异：不同性别之间相差两年左右，同性别之间相差四年左右。因此，同是初中学生，一部分学生生理已跨入青年期，而另一部分学生可能还停留在童年期。\\n2．心理上的原因。随着生理的变化，“成人感”的出现，初中学生心理产生“独立”，力求摆脱对成人的依赖，老师、家长在他们心目中的权威降低，同学之间相互影响增强。思维上发展了批判性，但由于经验的缺乏含有片面性和主观性；行为上出现“独特性”和“受暗示性”乃至“抗拒性”，即逆反心理；情绪上带有冲动性，不善于克制自己；兴趣和愿望上带有随意性、多变性、狂热性，常为了所谓讲“义气”而庇护同伴，或为同伴打抱不平；感情上具有“闭锁性”，而对于艰苦的学习活动特别重要的意志品质，则还处在比较软弱的状态。\\n3．环境的原因。心理学认为，个体的生物遗传因素规定了发展的潜在可能范围，而个体环境教育则确定他在此可能范围内的现实水平。环境条件有利与否对个体发展的现实水平起了决定性作用。\\n①家庭。社会的信仰、观念等社会化目标都是首先通过父母的过渡，以高度个性化了的、有选择的形式传递给儿童的。父母本身的个性特征、社会地位、教育水平、宗教信仰、价值标准等等都强烈地影响他们的后代。父母的教养方式、家庭结构、物质条件、人际环境、文化和情绪氛围，都在很大程度上影响着学生。\\n②学校。学校不仅是对学生传授文化科学知识，进行政治思想教育的社会基本教育单元，还是促进学生良好品格形成和发展的重要场所。学生在学校里形成良好的品格，才能顺利走向社会，适应社会生活。反之，则会发生各种问题。而现在的应试教育制度，像紧箍咒一样，时时冲击着素质教育，教师以升学率论质量给待遇，使一些教师对成绩好的学生倍加宠爱，对成绩差的学生则百般呵斥。更有少数教师将腐朽庸俗的人际关系引入师生和家长的关系，身教言传，污染了学生心灵；让孩子过早成人化、世故化。\\n③社会。社会上各种腐朽思想沉渣泛起，对学生负面影响很大。影视传媒、流失少年、勒索等等，浸染着学生稚嫩的心灵；电子游戏机、卡拉OK厅等，又使我们的孩子面临着极强的诱惑，意志薄弱者稍不留意，便坠入其间。\\n三、纠正初中学生的心理偏差的对策\\n为了纠正初中学生的心理偏差，我们必须对教育环境影响予以高度重视。在现有环境中，我们应做到：\\n1．坚持以德、智、体、美、劳全面的教育方针为指导思想进行教育管理，坚持“要成才先成人”的教育思想。\\n2．“学高为师，身正为范。”作为教师，必须加强道德修养，提高职业素质，全面关心和爱护每一位学生的身心健康发展。\\n3．以激励为心育的主要手段。我们要将思想教育和学生喜闻乐见的实践活动结合起来，不断提高学生对美的感受和鉴赏力，使其求真向善，茁壮成长。\\n4．形成教育合力。在抓好班集体建设的同时，我们必须密切联系家长，与家长一起研究分析学生，共同教育学生。\\n5．帮助学生正确认识、分析、评价自己的心理过程。让他们将社会化标准－－《中学生日常行为规范》逐渐内化，用以规范自己的言行，自觉抵制不良诱惑，不断提高自我意识水平和自我教育能力。\\n6．对各类心理偏差学生施以不同的教育。对有骄傲自负心理的学生施以“挫折教育”；对有自卑、胆怯畏惧心理的学生施以“磨难教育”；对有虚荣忌妒、趋同报复、庸俗心理的学生施以分辨真美善、假丑恶的“是非教育”等。\\n与此同时，还应努力提高、优化当代中学生的心理特点。\\n首先，作为家长必须转变观念。对自己的孩子，在作业和职业方面的“期望值”不能脱离子女的实际而好高骛远，每个孩子因智力因素、情趣爱好，性格意志和心理承力各不相同，如果孩子确实尽了自己的努力，而未达到你所期望的目标，不应过多责怪，更不能冷嘲热讽，惩罚打骂。诚然，家长望子成龙“天经地义”，无可厚非。但“龙”的内涵并不专指读大学、考研究生。“三百六十行，行行出状元”，如果每一位家长都能建立这样的“职业观”，让孩子在宽松的环境里读书，\\n其次，作为教育者----教师来说，则更要不断学习，及时吸收新鲜气息，不断提高自己的思想、政治教育水平，提高自己的专业知识和业务水平，做到不仅能教书育人，更能进行教育评价，尊重学生人格，依法执教，用先进的具有创造性的教育思想、理论、方法促进教育水平的提高，注重培养学生的全面发展，加强能力培养和思维训练，提高学生的综合素质。具体方法如下：\\n第一，让学生充分了解自己的心理特点，通过与周围的同学以及其他同龄人相比，通过同电影、小说电视里特定情景中的人物相比，如宣传奥斯特洛夫斯基、托尔斯泰、张海迪、贝多芬等等，通过对比，找出自己在哪些方面存在弱点，或者也可以通过父母、老师、同学对自己经常的评价了解自己在哪些方面存在不良心理特点，从而扬长避短。\\n第二，选择恰当的方法进行锻炼。例如：\\n1、教他们多读好书，如《周恩来》、《钢铁是怎样炼成的》等优化心理品质。人类的几千年文明，其智慧、经验、真知灼见，都浓缩于书中，如果多读好书，能经常与这样一些“高尚朋友”对话，听听他们的“指点”以此开阔视野，启迪智慧，这对优化学生的心理品质是大有裨益的，作为中学生，不仅要读好的故事书，还应该读一些伟人的传记，读一些思想、修养方面的书籍，并且养成做读书笔记的习惯。\\n2、鼓励学生参加社会活动，锻炼心理品质，如送“温暖小组”、“助残小分队”等活动的开展，都是锻炼心理品质行之有效的方法。\\n3、也要注重培养学生琴、棋、书、画、音、体、美等美育活动，有助于疏导、排解不良情绪，给人以美的熏陶和享受，从而对心理产生良性刺激。让美来充实孩子的精神生活，让美来帮助塑造孩子健康的心理。\\n4、在条件可能的情况下，可组织学生春游、郊游、野炊等活动，学生也可以利用寒、曙假、节假日到一些名胜古迹去游览、旅游、参观、陶冶自己的情操，走进大自然，亲近大自然，细心体会大自然，不仅能使人心胸开阔、情绪放松，精神振奋，还常能使人领悟到人生的真谛。\\n只有这样，优化了学生的心理特点，才能促使学生健康成长，从而成为新世纪的合格人才。',\n",
              " '我们生产的食品消泡剂，具有可以快速消除泡沫的特点。\\n丹东食品消泡剂相关内容：一般而言，纯水和纯表面活性剂不起泡，这是因为它们的表面和内部是均匀的，很难形成弹性薄膜，即使形成亦不稳定，会瞬间消失。\\n丹东食品消泡剂选择：\\n1. 相容性：相容性是指两种或者两种以上物质混合时，不产生相斥分离现象的能力，相容性好，消泡剂就能够长期、稳定、均匀地存在于体系中，进而发挥消抑泡的作用；反之，就会出现分层等现象，使消泡剂的消泡工作无法正常进行。\\n2. 消泡能力：消泡能力是消泡剂的最主要性能，鉴别此项性能的标准是在同等条件下，分别加入等量不同的消泡剂，观察消泡剂的消泡速度。',\n",
              " '程总在座谈中首先向学校的客人介绍了三一集团和北京三一重机的情况，以及在公司快速发展过程中对人才的渴求，指出通过校企联合，学校可以依靠企业的参与制定人才培养方案，使培养的人才更贴近市场，贴近企业，又可以借助企业的资源充实学校的办学实力。同时校企联合有利于企业的可持续发展。校企联合是企业实现人才战略的途径。企业在与高等职业教育合作过程中可以贯彻自己的培养意向，满足对生产第一线实用型人才的需求。\\n武汉交通职业学院盛建龙院长和河北工业职业技术学院李军锁副院长分别介绍了各自学校人才培养情况，并对三一集团的高速发展表示钦佩和赞赏，表示将和公司开展深入、全面的合作，优势互补，使学校和企业实现充分的资源共享，建立全方位长效合作机制。\\n本次联合办学签约仪式，是北京桩机高起点校企合作的开始。按照北京桩机人力资源提升计划，明年北京桩机将和所高职高专院校进行联合办学成立“三一班”，均为统招大专高技学历层次，涉及焊接、装配、机加工、售后服务等紧缺工种，“三一班”学员将达到近300人，为北京桩机的下一个五年跨越式发展打下良好的人才基础。',\n",
              " '此类溶剂很可能会随着生产过程挥发出来而导致污染，其排放主要发生在投料、反应、溶剂回收、过滤、离心、烘干、出料等操作单元。\\n制药废气危害\\n在医药化行业中大量使用有机溶剂(如DMF、苯系物、有机胺、乙酸乙酯、二氯甲烷、丙酮、甲醇、乙醇、丁酮、乙醚、二氯乙烷、醋酸、氯仿等)，挥发形成了具有刺激性气味和恶臭的气体，并具有一定毒害性，长期排放必然恶化区域大气环境质量，并对附近居民的身体产生危害。因此，有效治理制药行业VOCs污染已经成为亟待解决的重要问题。\\n制药废气成分\\nDMF、苯系物、有机胺、乙酸乙酯、二氯甲烷、丙酮、甲醇、乙醇、丁酮、乙醚、二氯乙烷、醋酸、氯仿等。\\n制药废气特点\\n(1)排放点多, 排放量大, 无组织排放严重。医药化工产品得率低, 溶剂消耗大, 溶剂废气排放点多, 且溶剂废气大多低空无组织排放, 溶剂废气浓度较高。\\n(2)间歇性排放多。反应过程基本上为间歇反应, 溶剂废气也呈间歇性排放。\\n(3)排放不稳定。溶剂废气成分复杂, 污染物种类和浓度变化大, 同一套装置在不同时期可能排放不同性质的污染物。\\n(4)溶剂废气影响范围广。溶剂废气中的VOCs大多具有恶臭性质, 嗅域值低, 易扩散, 影响范围广。\\n(5)在生产过程中易燃、易爆物质多, 反应过程激烈, 生产事故风险大。\\n制药废气处理方案/ Treatment plan\\n活性炭吸附方案\\n当制药废气进入吸附箱后进入活性炭吸附层，由于活性炭吸附表面上存在着未平衡和未饱和的分子引力或化学键力，因此当活性炭吸附剂的表面与气体接触时，就能吸引气体分子，使其浓聚并保持在固体表面，此现象称为吸附。利用活性炭吸附剂表面的吸附能力，使废气与大表面的多孔活性炭吸附剂相接触，废气中的污染物被吸附在活性炭表面上，使其与气体混合物分离，净化后的气体高空排放。\\nUV光解净化方案\\nUV光解废气处理技术是指利用高能UV紫外线光束分解空气中的氧分子产生游离氧（即活性氧），因游离氧所携带正负电子不平衡所以需与氧分子结合，进而产生臭氧，臭氧具有很强的氧化性，通过臭氧对有机废气、恶臭气体进行协同光解氧化作用，使有机废气、恶臭气体物质降解转化成低分子化合物、水和二氧化碳。\\n技术特点\\n（1）高效除恶臭：能高效去除挥发性有机物(VOC)、无机物、硫化氢、氨气、硫醇类等主要污染物，以及各种恶臭味气体，脱臭效率可达到95%以上，脱臭效果超过国家1993年颁布的恶臭污染物排放标准(GB14554-93)和1996年颁布的《大气污染物综合排放标准》(GB16297-1996)。\\n无需预处理：有机气体无需进行特殊的预处理，如加温、加湿等,设备工作环境温度在-30℃－95℃之间，湿度在30%－98%、PH值在2-11范围均可正常工作。\\n（2）无需添加任何物质：只需要设置相应的排风管道和排风动力，使恶臭气体以及工业废气通过UV光解废气净化设备进行脱臭分解净化，无需添加任何物质参与化学反应。\\n（3）适应性强：可适应中低浓度，不同工业废气物质的脱臭、净化处理，可每天24小时连续工作，运行稳定可靠。\\n（4）运行成本低：无任何机械动作，无噪音，无需专人管理和日常维护，只需作定期检查，设备能耗低，设备风阻低＜50pa,可节约大量排风动力能耗。\\n（5） 安全可靠：因采用光解原理，模块采取隔爆处理，消除了安全隐患，防火、防爆、防腐蚀性能高，设备性能安全稳定，特别适用于采油(气)田、石油化工、制药等防爆要求高的行业。\\n应用范围\\n印刷厂、印染厂、电子厂、塑料厂、涂料厂、家具厂、炼油厂、橡胶厂、化工厂、造纸厂、皮革厂、农药厂、制药厂、油漆厂、化肥厂、食品加工厂、饲料厂、香精香料厂、屠宰厂、污水处理厂、垃圾中转站、喷涂喷漆等恶臭气体、工业废气的净化处理。\\n催化燃烧方案\\n蓄热式热力氧化技术是把有机废气加热到760℃以上，使废气中的VOC在氧化分解成二氧化碳和水。氧化产生的高温气体流经特制的陶瓷蓄热体，使陶瓷体升温而“蓄热”，此“蓄热”用于预热后续进入的有机废气。从而节省废气升温的燃料消耗。\\n技术特点\\n（1）高浓度废气处理实现自供热燃烧，运行费用低，性价比合理。\\n（2）净化效率高，三室型RTO可达99.5%。\\n（3）采用陶瓷蓄热体作为热能回收，预热、蓄热交替运行，热效率≥95%。\\n（4）炉体钢结构牢靠，保温层厚实，运行安全可靠，稳定性高。\\n（5）PLC可编程自动化控制，自动化程度高。\\n（6）适用性广，可净化任何有机废气\\n（7）余热利用，经济效益高；多余的热能回用至烘房、烤箱等，烘房的加热不用额外消耗燃料或电能。\\n适用范围\\n石油、化工、塑料、橡胶、制药、印刷、家具、纺织印染、涂布、涂料、半导体制造、合成材料等行业产生中、高浓度大风量有机废气处理，可处理有机物质种 类包括苯类、酚类、醛类、酮类、醒类、酯 类、醇类、炷类等。',\n",
              " '白癜风病人调节心理要偶尔也要屈服。能屈能伸，能进能退，轻松自如；凡事认真，一味固执，肯定烦恼重重。其实，只要大前提不受影响，一些细枝末节上的让步、妥协，是明智的，也是一种大智若愚的姿态。\\n转移治愈力：很多人的烦恼是由于对于生活的期望值过高而造成的，一旦这些期望没能实现，烦恼也就随之而来。因此，正确的面对现实，踏实做自己。尽量克制自己的情绪，并将注意力转移到学习、工作、娱乐或者其他感兴趣的方面，可以通过听歌、跳舞等娱乐活动来忘记心中的苦闷，还可以通过体育运动来消除不良的情绪，这样就不至于越想越难过了。贵州白癜风\\n白癜风患者怎样更好的减轻心理压力生活中要消除各种精神刺激，白癜风患者心理努力改善精神状态和不良的生活、工作环境，保持良好的心理，增强自身免疫功能，及早发现，及时治疗，并持之以恒。而且，在治疗的过程中，还要根据不同的病因，采用不同的治疗方法，同时要保持精神乐观，心情舒畅，切勿悲观急躁，尽力解除一切不必要的思想顾虑。\\n专家建议一旦发现在即皮肤出现白斑最好还是到正规的医院去进行确诊，然后在医生的指导下进行治疗。不要自己判断完了就自行用药，以免给自己带来不必要的伤害。',\n",
              " '对全校教学保障、教学建设、教学管理、教学运行和教学改革等进行质量监控和评价。\\n贯彻执行党的教育方针和上级教育部门文件精神，制定并组织实施学校教学质量监控与评估的相关文件及规章制度。\\n依据《博鱼平台入口(中国)有限公司各主要教学环节质量标准和评价方案》等规章制度，定期开展课堂教学、课程考核、毕业设计（论文、创作）、实验（实践）教学等主要教学环节的检查与评价工作，规范教学行为。\\n组织学校本科教学基本状态数据库的采集工作，进行数据整理、分析。充分利用信息技术，全面如实反映学校的办学状况以及在教学质量提升方面采取的措施和存在的问题，建立本科教学工作及其质量常态监控机制。\\n积极开展各类教学状况信息的收集和整理，并做好分析、反馈和整改工作。组织学校年度本科教学质量报告的撰写和发布工作，在客观反映学校教学质量的同时，分析学校教学质量发展的动态趋势，并揭示学校在人才培养和教学质量中存在的问题，提出具体的改进措施。',\n",
              " '有趣的是，库里在第三节上篮时被防守球员犯规，但裁判并未理会，怒不可遏的库里对着裁判一顿输出，随后怒吃一T。这彻底激怒了他，在随后的75秒内，库里连中3记三分带走比赛，而在命中本场比赛第7记三分后，库里还学裁判比出给T的手势热烈庆祝！在赛后采访时，库里谈到比T的庆祝手势：“很明显，我认为我被犯规了，所以我想发泄情绪，然后你就会放开了，并且专心的打篮球。',\n",
              " '担任地点省市的区域运营中心的办理作业。承受总部相关KPI查核。\\n1、了解新闻职业或媒体相关运营运营岗位，其间，应聘区域运营中心主任有3年以上当地干流媒体作业经验者优先，应聘事务主管有2年以上当地干流媒体作业经验者优先。\\n2、交流才能强，抗压才能强，长于处理复杂情况，了解GR作业优先，能独立完结策划计划优先。具有独立开发客户才能。\\n北京、天津、河北、山西、黑龙江、吉林、辽宁、上海、江苏、浙江、安徽、江西、福建、山东、河南、湖北、湖南、广东、海南、重庆、四川、贵州、云南、陕西等。']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hOqd0fND26k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## def train function and loading the dataset"
      ],
      "metadata": {
        "id": "ZAPRP-AoJCct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(dataset_path)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [0.9, 0.1])\n",
        "train_loader = DataLoader(train_dataset, batch_size = 12, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 12, shuffle = False)\n"
      ],
      "metadata": {
        "id": "NgNUU-pxJJSl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(GPTConfig())\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4)\n",
        "\n",
        "# cosine learning rate\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 1000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt-B_uYHNCl-",
        "outputId": "bc0ab1b3-85e5-4efe-9410-160353ebaf05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 91765248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kauWdGC1JpO_",
        "outputId": "afcdef42-b9ab-47e9-a90e-b69042eb11fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 512]) torch.Size([12, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, scheduler,train_loader, val_loader,device):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for batch_idx, (x,y) in enumerate(train_loader):\n",
        "    # move data onto devices\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    # forward probagation\n",
        "    logits, loss = model(x, targets = y)\n",
        "\n",
        "    # back propagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # adjust learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    total_loss + loss.item()\n",
        "\n",
        "    if batch_idx % 100 ==0:\n",
        "      print(f'epoch:{epoch}, Batch:{batch_idx}, loss:{loss.item():.4f}')\n",
        "    return total_loss\n",
        "\n",
        "def eval(model, val_loader, device):\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      logits, loss = model(x, targets = y)\n",
        "      val_loss += loss.item()\n",
        "  return val_loss / len(val_loader)\n",
        "\n",
        "# run epoch\n",
        "for epoch in range(2):\n",
        "  train_loss = train(model, optimizer, scheduler, train_loader, val_loader, device)\n",
        "  val_loss = eval(model, val_loader, device)\n",
        "  print(f'epoch:{epoch}, train_loss:{train_loss:.4f}, val_loss:{val_loss:.4f}')\n",
        "\n",
        "  # save the model\n",
        "  avg_val_loss = val_loss / len(val_loader)\n",
        "  checkpoint = {\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'scheduler_state_dict': scheduler.state_dict(),\n",
        "      'avg_val_loss': avg_val_loss\n",
        "  }\n",
        "  torch.save(checkpoint, 'checkpoint.pth')\n"
      ],
      "metadata": {
        "id": "ydADjFK6F-xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8975bb8-02f6-40a7-c7d7-cb6d1a09639a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0, Batch:0, loss:11.0228\n",
            "epoch:0, train_loss:0.0000, val_loss:9.8709\n",
            "epoch:1, Batch:0, loss:9.8877\n",
            "epoch:1, train_loss:0.0000, val_loss:9.2978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iV0GDWe3L1HH"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}